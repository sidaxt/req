{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done - upload()\n",
    "# async def upload():\n",
    "try:\n",
    "    global img_count\n",
    "    start_time_upload_total=time.time()\n",
    "\n",
    "    files = \"C:/Users/ssirish/Downloads\"\n",
    "    # files = await request.files\n",
    "    # print(files, \"upload files\")\n",
    "    # Define a temporary directory to save the uploaded files\n",
    "    tempdir = \"./tempfile\"\n",
    "    # Ensure the temporary directory exists, create it if not\n",
    "    # os.makedirs('ssirish@dsi.com', exist_ok=True)\n",
    "    os.makedirs(os.path.join(tempdir, 'ssirish@dsi.com'), exist_ok=True)\n",
    "\n",
    "    img_extensions = (\".jpg\", \".png\", \".jpeg\", \".bmp\", \".tiff\", \".tif\", \".gif\", \".webp\", \".JPG\", \".PNG\", \".JPEG\", \".BMP\", \".TIFF\", \".TIF\", \".GIF\", \".WEBP\")\n",
    "    structured_extensions = (\".csv\", \".xlsx\")\n",
    "    unstructured_extensions = (\".pdf\", \".docx\", \".pptx\", \".txt\")\n",
    "    stored_img_flag = False\n",
    "    total_size = 0\n",
    "    unstructured_files = []\n",
    "    \n",
    "    # ## check if there is already csv/excel uploaded.\n",
    "    #tempath = os.path.join(tempdir, 'ssirish@dsi.com', file.filename)\n",
    "    folder_files = os.listdir(os.path.join(tempdir, 'ssirish@dsi.com'))\n",
    "    print(folder_files)\n",
    "    # folder_files = os.listdir(os.path.join(tempdir, output_folder))\n",
    "    file_name = None\n",
    "    for file_name in folder_files:\n",
    "        if file_name.endswith(img_extensions):\n",
    "            stored_img_flag = True\n",
    "        if file_name.endswith(structured_extensions):\n",
    "            print('error for csv excel')\n",
    "            # return \"done\"\n",
    "            # return jsonify({\"status\" : 'delete csv_excel', \"error\" : \"CSV/Excel already uploaded, Clear it to proceed\"}), 250\n",
    "    \n",
    "\n",
    "    file_count = 0\n",
    "    csv_excel_file_count = 0\n",
    "    csv_excel_flag = False\n",
    "    img_flag = False\n",
    "    unstructured_flag = False\n",
    "\n",
    "    for file in files:\n",
    "        # print(file, \"files\", files[file].filename)\n",
    "        # Print information about each file\n",
    "        file_count += 1\n",
    "        print(f\"Processing file: {files[file].filename}\")\n",
    "        \n",
    "        if files[file].filename.endswith(img_extensions):\n",
    "            img_flag = True\n",
    "\n",
    "        if files[file].filename.endswith(structured_extensions):\n",
    "            csv_excel_file_count +=1\n",
    "            csv_excel_flag = True\n",
    "\n",
    "        if files[file].filename.endswith(unstructured_extensions):\n",
    "            unstructured_flag = True\n",
    "\n",
    "        # if (csv_excel_flag == True) and (csv_excel_file_count > 1):\n",
    "        #     return jsonify({\"status\" :'csv_excel_error', 'error' : \"Upload single CSV/Excel file\"}), 400\n",
    "        \n",
    "        # if (csv_excel_flag == True) and (unstructured_flag == True):\n",
    "        #     return jsonify({\"status\" :'structured_unstructured_error', 'error' : \"structured_unstructured_error\"}), 280\n",
    "        \n",
    "        # if (csv_excel_flag == True) and os.path.exists(os.path.join('vector_stored', 'ssirish@dsi.com')):\n",
    "        #     return jsonify({\"status\" :\"csv_excel_error\", 'error' : \"Delete already uploaded files, and try uploading.\"}), 260\n",
    "        \n",
    "        # if (img_flag == True) and os.path.exists(os.path.join('vector_stored', 'ssirish@dsi.com')):\n",
    "        #     return jsonify({\"status\" :\"csv_excel_error\", 'error' : \"Delete already uploaded files, and try uploading.\"}), 265\n",
    "        \n",
    "        # if (img_flag == True) and (unstructured_flag == True):\n",
    "        #     return jsonify({\"status\" :\"image_unstructured_error\", 'error' : \"image_unstructured_error\"}), 270\n",
    "        \n",
    "        # if (img_flag == True) and (csv_excel_flag == True):\n",
    "        #     return jsonify({\"status\" :\"image_structured_error\", 'error' : \"image_structured_error\"}), 290\n",
    "        \n",
    "        # if (stored_img_flag == True) and ((unstructured_flag == True) or (csv_excel_flag == True)):\n",
    "        #     return jsonify({\"status\" :\"delete_previously_uploaded_img_files\", 'error' : \"delete_previously_uploaded_img_files\"}), 291\n",
    "    print(\"File_count\",file_count)\n",
    "    \n",
    "        \n",
    "    for file in files:\n",
    "        print(f\"Processing file2: {files[file].filename}\")\n",
    "        img_flag = False\n",
    "        csv_excel_flag = False\n",
    "        if files[file].filename.endswith(img_extensions):\n",
    "            img_flag = True\n",
    "        if files[file].filename.endswith(structured_extensions):\n",
    "            csv_excel_flag = True\n",
    "        if img_flag:\n",
    "            _, file_extension = os.path.splitext(files[file].filename)\n",
    "        \n",
    "        user_dir = os.path.join(tempdir, 'ssirish@dsi.com')\n",
    "        # user_dir = os.path.join(tempdir, output_folder)\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "        # Save the file\n",
    "        file_path = os.path.join(user_dir, files[file].filename)\n",
    "        await files[file].save(file_path)\n",
    "\n",
    "        # Calculate the total size of all files in the directory\n",
    "        total_size = 0\n",
    "\n",
    "        # Iterate over all files in the user directory\n",
    "    for file_name in os.listdir(user_dir):\n",
    "        file_path = os.path.join(user_dir, file_name)\n",
    "        \n",
    "        # Check if it's a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Add the file size to the total\n",
    "            total_size += os.path.getsize(file_path)\n",
    "            print(total_size)\n",
    "\n",
    "    if files[file].filename.endswith(unstructured_extensions):\n",
    "        file_path_list = []\n",
    "        files = os.listdir(os.path.join(tempdir, 'ssirish@dsi.com'))\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(os.path.join(tempdir, 'ssirish@dsi.com'), file_name)               \n",
    "            file_path_list.append(file_path) \n",
    "        \n",
    "        for i in file_path_list:\n",
    "            if i.endswith('.docx')  or i.endswith('.txt'):\n",
    "                pdf_path = convert_docx_to_pdf(i, None)\n",
    "                if os.path.exists(i):\n",
    "                    os.remove(i)\n",
    "                i = pdf_path  # Update the file path to the PDF path\n",
    "                print(i, \"i 688\")# if i.endswith('.docx') or i.endswith('.pptx') or i.endswith('.txt'):\n",
    "            \n",
    "\n",
    "        # Call create_index function for this file\n",
    "        await create_index(user_name='ssirish@dsi.com')\n",
    "        for i in file_path_list:\n",
    "            if i.endswith('.pptx') :\n",
    "                pdf_path = convert_docx_to_pdf(i, None)\n",
    "                if os.path.exists(i):\n",
    "                    os.remove(i)\n",
    "                i = pdf_path\n",
    "                print(i, \"i 688\")# if i.endswith('.docx') or i.endswith('.pptx') or i.endswith('.txt'):\n",
    "            \n",
    "\n",
    "            # source_container_name = \"bulk-upload-qna\"\n",
    "            source_container_name = os.getenv('AZURE_BULK_UPLOAD_CONTAINER_NAME')\n",
    "            connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "            # connection_string = \"DefaultEndpointsProtocol=https;AccountName=sapocopenai;AccountKey=H30mVmhmyKpFmLUkFSKpDO3CUe+jbcG8aGZ8TgCRNTQj5Ac5HB+649BzYypyo9eW0W9BRy9Z0oFr+ASt6hAVYw==;EndpointSuffix=core.windows.net\"\n",
    "            await upload_file_to_azure(source_container_name, i, connection_string, 'ssirish@dsi.com')\n",
    "            print(\"here 594\")\n",
    "            # print(i)\n",
    "            # print(i.split('\\\\')[-1])\n",
    "            # logging.debug(i.split('\\\\')[-1], \"698\")\n",
    "            blob_name = 'ssirish@dsi.com' + \"/\" + os.path.basename(i)\n",
    "        \n",
    "            blob_folder = \"blob/\" + 'ssirish@dsi.com'\n",
    "\n",
    "        source_container_name = os.getenv('AZURE_BULK_UPLOAD_CONTAINER_NAME')\n",
    "        connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "        # source_container_name = \"bulk-upload-qna\"\n",
    "        # connection_string = \"DefaultEndpointsProtocol=https;AccountName=sapocopenai;AccountKey=H30mVmhmyKpFmLUkFSKpDO3CUe+jbcG8aGZ8TgCRNTQj5Ac5HB+649BzYypyo9eW0W9BRy9Z0oFr+ASt6hAVYw==;EndpointSuffix=core.windows.net\"\n",
    "        # os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "        for file_name in os.listdir(user_dir):\n",
    "            file_path = os.path.join(user_dir, file_name)\n",
    "\n",
    "            # Check if it's a file (not a directory)\n",
    "            if os.path.isfile(file_path):\n",
    "            # Upload the current file to Azure Blob Storage\n",
    "                await upload_file_to_azure(source_container_name, file_path, connection_string, 'ssirish@dsi.com')\n",
    "        end_time_upload_total = time.time()\n",
    "\n",
    "        execution_time_upload = end_time_upload_total - start_time_upload_total\n",
    "        print(f\"Time taken for document Upload: {execution_time_upload:.6f} seconds\")        \n",
    "        # return jsonify({\"status\": \"success\", \"test_purpose\": \"test_purpose\"}), 200\n",
    "\n",
    "    tempath = os.path.join(tempdir, 'ssirish@dsi.com', files[file].filename)\n",
    "    # if img_flag:\n",
    "    #     if (file_extension == '.tiff') or (file_extension == '.bmp') or (file_extension == '.tif') or (file_extension == '.TIFF') or (file_extension == '.TIF') or (file_extension == '.BMP'):\n",
    "    #             image = Image.open(tempath)\n",
    "    #             image = image.convert('RGB')\n",
    "    #             output_path = os.path.splitext(tempath)[0] + '.jpeg'\n",
    "    #             image.save(output_path, quality=100)\n",
    "    #             # print(\"converted image Saved\", output_path)\n",
    "    #             os.remove(tempath)\n",
    "\n",
    "    \n",
    "    print(csv_excel_flag, \"excel_csv_flag\")\n",
    "    if (not csv_excel_flag) and (not img_flag):\n",
    "        file_path_list = []\n",
    "        scanned_file_path_list = []\n",
    "        token_limit_crossed = False\n",
    "        max_token_limit = 1000000\n",
    "        total_tokens = 0\n",
    "        files = os.listdir(os.path.join(tempdir, 'ssirish@dsi.com'))  \n",
    "        print(files, \"652\")        \n",
    "\n",
    "        for file_name in files:\n",
    "            file_tokens = 0\n",
    "            print(file_name, \"filename inside upload\")\n",
    "            file_path = os.path.join(os.path.join(tempdir, 'ssirish@dsi.com'), file_name)\n",
    "            # file_path = os.path.join(file_name)\n",
    "            print(file_path, \"file_path 659\")\n",
    "\n",
    "            file_tokens = token_counter(file_path)\n",
    "            total_tokens = total_tokens + file_tokens\n",
    "            \n",
    "            if file_tokens < 10:\n",
    "                scanned_file_path_list.append(file_path)\n",
    "                print(scanned_file_path_list, \"scanned_file_path_list\")\n",
    "            else:\n",
    "                file_path_list.append(file_path)\n",
    "                print(file_path_list, \"file_path_list\")\n",
    "\n",
    "            # print(\"file_name\", file_name, file_path, token_counter(file_path))\n",
    "            if total_tokens > max_token_limit:\n",
    "                token_limit_crossed = True\n",
    "                # print(\"total_tokens_crossed_limit\", total_tokens)\n",
    "                shutil.rmtree(os.path.join(tempdir, 'ssirish@dsi.com'))\n",
    "                # return jsonify({\"status\" :'file_limit_exceeds', 'error' : \"Upload small size files, or try with few number of files\"}), 500\n",
    "        \n",
    "        # print(token_limit_crossed)\n",
    "        # print(\"total tokens\", total_tokens)\n",
    "        # print(\"total tokens\", total_tokens)\n",
    "\n",
    "        if not token_limit_crossed:\n",
    "            \n",
    "            for i in file_path_list:\n",
    "                if i.endswith('.docx') or i.endswith('.pptx') or i.endswith('.txt'):\n",
    "                    # pdf_path = convert_docx_to_pdf(i, None)\n",
    "                    # if os.path.exists(i):\n",
    "                    print(\"Hello122\")\n",
    "                    #     os.remove(i)\n",
    "                    # i = pdf_path\n",
    "                    # print(i, \"i 688\")\n",
    "\n",
    "                # source_container_name = \"file-upload\"\n",
    "                # connection_string= \"DefaultEndpointsProtocol=https;AccountName=sapocopenai;AccountKey=H30mVmhmyKpFmLUkFSKpDO3CUe+jbcG8aGZ8TgCRNTQj5Ac5HB+649BzYypyo9eW0W9BRy9Z0oFr+ASt6hAVYw==;EndpointSuffix=core.windows.net\"\n",
    "                # os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "                source_container_name = os.getenv('AZURE_TARGET_CONTAINER_NAME_FILE_UPLOAD')\n",
    "                connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "                await upload_file_to_azure(source_container_name, i, connection_string, 'ssirish@dsi.com')\n",
    "                print(\"here 594\")\n",
    "                # print(i)\n",
    "                # print(i.split('\\\\')[-1])\n",
    "                # logging.debug(i.split('\\\\')[-1], \"698\")\n",
    "                blob_name = 'ssirish@dsi.com' + \"/\" + os.path.basename(i)\n",
    "                # blob_name = 'ssirish@dsi.com' + \"/\" + i.split('\\\\')[-1]\n",
    "                # print(blob_name, \"700\")\n",
    "                # logging.debug(blob_name, \"blob_name 701\")\n",
    "                file_url = await generate_previewable_url(source_container_name, blob_name)\n",
    "                # file_url = await generate_target_uri(source_container_name,files[file].filename, \"\", 'ssirish@dsi.com')\n",
    "                print(\"*****************file_url*************************\")\n",
    "                # print(file_url)\n",
    "                # logging.debug(\"*****************file_url*************************\")\n",
    "                # logging.debug(file_url)\n",
    "            \n",
    "                vector_store = await create_vectorstore(file = i, user_name = 'ssirish@dsi.com', file_url = file_url)                                        \n",
    "                    \n",
    "                if os.path.exists(i):\n",
    "                    os.remove(i)\n",
    "                    # print(\"file_path deleted\", i)\n",
    "            for j, i in enumerate(scanned_file_path_list):\n",
    "                folder_path = os.path.join(tempdir, 'ssirish@dsi.com', os.path.splitext(os.path.basename(i))[0])\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.makedirs(folder_path)\n",
    "                # await scannned_document().create_vstore(i, folder_path, 'ssirish@dsi.com')\n",
    "                if os.path.exists(i):\n",
    "                    os.remove(i)\n",
    "\n",
    "    end_time_upload_total = time.time()\n",
    "\n",
    "    execution_time_upload = end_time_upload_total - start_time_upload_total\n",
    "    print(f\"Time taken for document Upload: {execution_time_upload:.6f} seconds\")\n",
    "    # return jsonify({\"status\": \"success\", \"test_purpose\": \"test_purpose\"}), 200\n",
    "except Exception as e:\n",
    "    tempdir = \"./tempfile\"\n",
    "    # remove_directory(os.path.join(tempdir, 'ssirish@dsi.com'))\n",
    "    print(\"error occured:\", e)\n",
    "    # return jsonify(status='try_after_some_time', error=str(e)), 600\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
