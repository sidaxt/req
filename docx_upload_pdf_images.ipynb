{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libreoffice --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial - Copy.docx\"  # Path to your input file\n",
    "output_folder = \"C:/Users/ssirish/Downloads/Sharepoint files download/output\"  # Path to your output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libreoffice --headless --convert-to pdf input.docx --outdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soffice_cmd = 'C:/Program Files/LibreOffice/program/soffice.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'libreoffice' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!libreoffice --headless --convert-to pdf input_docx --outdir .\n",
    "# \"C:/Users/ssirish/Downloads/Sharepoint files download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docx import Document\n",
    "\n",
    "# def split_word_doc(input_file, output_folder):\n",
    "#     # Load the original document\n",
    "#     doc = Document(input_file)\n",
    "    \n",
    "#     # Start tracking content for pages\n",
    "#     pages = []\n",
    "#     current_page = []\n",
    "    \n",
    "#     # Approximation: Splitting content based on paragraphs as pages aren't well-defined in python-docx\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         current_page.append(paragraph.text)\n",
    "#         if \"PAGE_BREAK\" in paragraph.text:  # Placeholder for manual page breaks or end of a page\n",
    "#             pages.append(current_page)\n",
    "#             current_page = []\n",
    "    \n",
    "#     # Add the last page if not already added\n",
    "#     if current_page:\n",
    "#         pages.append(current_page)\n",
    "    \n",
    "#     # Save each page into a new Word document\n",
    "#     for i, page_content in enumerate(pages, start=1):\n",
    "#         new_doc = Document()\n",
    "#         for line in page_content:\n",
    "#             new_doc.add_paragraph(line)\n",
    "#         output_file = f\"{output_folder}/page_{i}.docx\"\n",
    "#         new_doc.save(output_file)\n",
    "#         print(f\"Saved: {output_file}\")\n",
    "\n",
    "# # Usage\n",
    "# # input_file = \"input.docx\"  # Path to your input file\n",
    "# # input_file = \"C:\\Users\\a6006\\OneDrive - Axtria\\Documents\\DSI_New\\Sharepoint files download\\Enhertu-Biomarker Analysis in the DAISY Trial.docx\"  # Path to your input file\n",
    "# input_file = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial.docx\"  # Path to your input file\n",
    "# output_folder = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/output\"  # Path to your output folder\n",
    "# # output_folder = \"C:\\Users\\a6006\\OneDrive - Axtria\\Documents\\DSI_New\\Sharepoint files download\\output\"  # Path to your output folder\n",
    "# # output_folder = \"output\"  # Path to your output folder\n",
    "# split_word_doc(input_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_Body' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ssirish/Downloads/Sharepoint files download/output\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your output folder\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# output_folder = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/output\"  # Path to your output folder\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# # output_folder = \"C:\\Users\\a6006\\OneDrive - Axtria\\Documents\\DSI_New\\Sharepoint files download\\output\"  # Path to your output folder\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# # output_folder = \"output\"  # Path to your output folder\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43msplit_word_doc_with_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m, in \u001b[0;36msplit_word_doc_with_images\u001b[1;34m(input_file, output_folder)\u001b[0m\n\u001b[0;32m     32\u001b[0m         new_doc\u001b[38;5;241m.\u001b[39madd_paragraph(element\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m element\u001b[38;5;241m.\u001b[39mtag\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtbl\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Table (if exists)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m         \u001b[43mnew_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(element)\n\u001b[0;32m     35\u001b[0m timevariable \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mlocaltime())\n\u001b[0;32m     36\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimevariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_Body' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "import time\n",
    "\n",
    "def split_word_doc_with_images(input_file, output_folder):\n",
    "    # Load the original document\n",
    "    doc = Document(input_file)\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Initialize variables for pages\n",
    "    pages = []\n",
    "    current_page = []\n",
    "\n",
    "    for element in doc.element.body:\n",
    "        if element.tag.endswith('sectPr'):  # End of a section/page\n",
    "            pages.append(current_page)\n",
    "            current_page = []\n",
    "        else:\n",
    "            current_page.append(element)\n",
    "    \n",
    "    if current_page:\n",
    "        pages.append(current_page)\n",
    "\n",
    "    # Save each page into a new Word document\n",
    "    for i, page_elements in enumerate(pages, start=1):\n",
    "        new_doc = Document()\n",
    "        for element in page_elements:\n",
    "            if element.tag.endswith('p'):  # Paragraph\n",
    "                new_doc.add_paragraph(element.text)\n",
    "            elif element.tag.endswith('tbl'):  # Table (if exists)\n",
    "                new_doc._body.append(element)\n",
    "        timevariable = time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n",
    "        output_file = os.path.join(output_folder, f\"page_{i}_{timevariable}.docx\")\n",
    "        new_doc.save(output_file)\n",
    "        print(f\"Saved: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "# # input_file = \"input.docx\"  # Path to your input file\n",
    "# # input_file = \"C:\\Users\\a6006\\OneDrive - Axtria\\Documents\\DSI_New\\Sharepoint files download\\Enhertu-Biomarker Analysis in the DAISY Trial.docx\"  # Path to your input file\n",
    "# input_file = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial.docx\"  # Path to your input file\n",
    "input_file = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Overview of the DAISY Trial.docx\"  # Path to your input file\n",
    "output_folder = \"C:/Users/ssirish/Downloads/Sharepoint files download/output\"  # Path to your output folder\n",
    "# output_folder = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/output\"  # Path to your output folder\n",
    "# # output_folder = \"C:\\Users\\a6006\\OneDrive - Axtria\\Documents\\DSI_New\\Sharepoint files download\\output\"  # Path to your output folder\n",
    "# # output_folder = \"output\"  # Path to your output folder\n",
    "split_word_doc_with_images(input_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/ssirish/Downloads/Sharepoint files download/output\\page_1_20241214165119.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import time\n",
    "\n",
    "def split_word_doc_with_images(input_file, output_folder):\n",
    "    # Load the original document\n",
    "    doc = Document(input_file)\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    import os\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Splitting content into pages manually based on placeholder or logic\n",
    "    pages = []\n",
    "    current_page = []\n",
    "\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if \"PAGE_BREAK\" in paragraph.text:  # Placeholder to simulate a page break\n",
    "            pages.append(current_page)\n",
    "            current_page = []\n",
    "        else:\n",
    "            current_page.append(paragraph)\n",
    "\n",
    "    # Add the last page if not added\n",
    "    if current_page:\n",
    "        pages.append(current_page)\n",
    "\n",
    "    # Save each page as a new document\n",
    "    for i, page_content in enumerate(pages, start=1):\n",
    "        new_doc = Document()\n",
    "        for paragraph in page_content:\n",
    "            # Add paragraphs to the new document\n",
    "            new_doc.add_paragraph(paragraph.text)\n",
    "        timevariable = time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n",
    "        output_file = os.path.join(output_folder, f\"page_{i}_{timevariable}.docx\")\n",
    "        new_doc.save(output_file)\n",
    "        print(f\"Saved: {output_file}\")\n",
    "\n",
    "# Usage\n",
    "# input_file = \"input.docx\"  # Replace with your actual file\n",
    "# input_file = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial.docx\"  # Path to your input file\n",
    "# output_folder = \"C:/Users/a6006/OneDrive - Axtria/Documents/DSI_New/Sharepoint files download/output\"  # Path to your output folder\n",
    "input_file = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Overview of the DAISY Trial.docx\"  # Path to your input file\n",
    "output_folder = \"C:/Users/ssirish/Downloads/Sharepoint files download/output\"  # Path to your output folder\n",
    "\n",
    "# output_folder = \"output_pages\"\n",
    "split_word_doc_with_images(input_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside word to pdf\n",
      "Error converting Word to PDF: [WinError 2] The system cannot find the file specified\n",
      "None pdf_file content\n",
      "Failed to convert Word to PDF.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import subprocess\n",
    "\n",
    "def convert_word_to_pdf(input_docx, output_pdf):\n",
    "    \"\"\"\n",
    "    Converts a Word document to PDF using LibreOffice in headless mode.\n",
    "    \"\"\"\n",
    "    print('inside word to pdf')\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", input_docx],\n",
    "            check=True\n",
    "        )\n",
    "        print('completion of subprocess')\n",
    "        pdf_name = os.path.splitext(input_docx)[0] + \".pdf\"\n",
    "        print(pdf_name, 'pdf_name content')\n",
    "        if not os.path.exists(pdf_name):\n",
    "            raise FileNotFoundError(f\"PDF not created: {pdf_name}\")\n",
    "        return pdf_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting Word to PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_pdf_into_pages(input_pdf, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a PDF into single-page PDFs.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for page_number, page in enumerate(reader.pages, start=1):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(page)\n",
    "\n",
    "        output_pdf = os.path.join(output_folder, f\"page_{page_number}.pdf\")\n",
    "        with open(output_pdf, \"wb\") as output_file:\n",
    "            writer.write(output_file)\n",
    "\n",
    "        print(f\"Saved: {output_pdf}\")\n",
    "\n",
    "def split_word_to_pdf_pages(input_docx, output_folder):\n",
    "    \"\"\"\n",
    "    Converts a Word document to PDF and splits it into single-page PDFs.\n",
    "    \"\"\"\n",
    "    # Step 1: Convert Word to PDF\n",
    "    pdf_file = convert_word_to_pdf(input_docx, os.path.basename(input_docx).replace('.docx', '.pdf'))\n",
    "    print(pdf_file, 'pdf_file content')\n",
    "    if not pdf_file:\n",
    "        print(\"Failed to convert Word to PDF.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Split PDF into single-page PDFs\n",
    "    split_pdf_into_pages(pdf_file, output_folder)\n",
    "\n",
    "# Usage\n",
    "# input_file = \"input.docx\"  # Replace with your actual file\n",
    "input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial - Copy.docx\"  # Path to your input file\n",
    "output_folder = \"C:/Users/ssirish/Downloads/Sharepoint files download/output\"  # Path to your output folder\n",
    "# output_folder = \"output_pages\"\n",
    "split_word_to_pdf_pages(input_docx, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install aspose-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aspose.words.saving.SaveOutputParameters object at 0x000002ED6F988B90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aspose.words as aw\n",
    "\n",
    "# input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/file_uploads_bkp/FAQs About Clinical Studies.docx\"  # Path to your input file\n",
    "# output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/FAQs About Clinical Studies - 4.pdf\"  # Path to your output folder\n",
    "\n",
    "input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Overview of the DAISY Trial.docx\"  # Path to your input file\n",
    "output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/Enhertu-Overview of the DAISY Trial - Copy - 4.pdf\"  # Path to your output folder\n",
    "\n",
    "doc = aw.Document(input_docx)\n",
    "doc.save(output_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "\n",
    "# Download Pandoc to a temporary location\n",
    "pypandoc.download_pandoc()\n",
    "\n",
    "input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Overview of the DAISY Trial.docx\"  # Path to your input file\n",
    "output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/Enhertu-Overview of the DAISY Trial - Copy - 5.pdf\"  # Path to your output folder\n",
    "\n",
    "pypandoc.convert_file(input_docx, 'pdf', outputfile=output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from win32com import client\n",
    "import time\n",
    "\n",
    "def convert_word_to_pdf(input_docx, output_pdf):\n",
    "    print('entered loop')\n",
    "    word = client.Dispatch(\"Word.Application\")\n",
    "    doc = word.Documents.Open(os.path.abspath(input_docx))\n",
    "    print('doc print equals')\n",
    "    doc.SaveAs(os.path.abspath(output_pdf), FileFormat=17)  # FileFormat=17 is PDF\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "    print(f\"Converted: {output_pdf}\")\n",
    "\n",
    "# Usage\n",
    "# input_docx = \"input.docx\"\n",
    "# output_pdf = \"output.pdf\"\n",
    "# input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Biomarker Analysis in the DAISY Trial - Copy.docx\"  # Path to your input file\n",
    "# input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/Enhertu-Overview of the DAISY Trial.docx\"  # Path to your input file\n",
    "input_docx = \"C:/Users/ssirish/Downloads/Sharepoint files download/file_uploads_bkp/FAQs About Clinical Studies.docx\"  # Path to your input file\n",
    "output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/FAQs About Clinical Studies - 3.pdf\"  # Path to your output folder\n",
    "# output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/Enhertu-Overview of the DAISY Trial - Copy - 3.pdf\"  # Path to your output folder\n",
    "# output_pdf = \"C:/Users/ssirish/Downloads/Sharepoint files download/output/Enhertu-Biomarker Analysis in the DAISY Trial - Copy - 3.pdf\"  # Path to your output folder\n",
    "convert_word_to_pdf(input_docx, output_pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
